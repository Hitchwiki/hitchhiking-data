{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "import folium\n",
    "import folium.plugins\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import osmnx\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "from matplotlib import pyplot as plt\n",
    "from osmnx._errors import InsufficientResponseError\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "from shapely.geometry import (LineString, MultiPolygon, Point,\n",
    "                              Polygon)\n",
    "from shapely.ops import nearest_points\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "pd.options.display.max_rows = 4000\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "osmnx.settings.use_cache = True\n",
    "osmnx.settings.log_console = False\n",
    "\n",
    "import logging\n",
    "\n",
    "from stats import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_crs = 'EPSG:3857'\n",
    "\n",
    "# used for gps - geographic crs\n",
    "standard_crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_from_country(region=\"Germany\", level=\"country\"):\n",
    "    file = \"./points.sqlite\"\n",
    "    points = pd.read_sql(\"select * from points where not banned\", sqlite3.connect(file))\n",
    "    region_osm_data = osmnx.geocode_to_gdf({level: region})\n",
    "    polygon = region_osm_data.iloc[0].geometry\n",
    "    # TODO repeated pattern?\n",
    "    points = gpd.GeoDataFrame(points, geometry=gpd.points_from_xy(points.lon, points.lat))\n",
    "    points = points[points.progress_apply(lambda point: point[\"geometry\"].within(polygon), axis=1)]\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO delete places in water\n",
    "# TODO write test for the single components?\n",
    "\n",
    "# select the country here\n",
    "# contains all entries for the same place as single samples\n",
    "region = \"Germany\"\n",
    "level = \"country\"\n",
    "\n",
    "logging.basicConfig(filename=f'./logging/logging_{region}.log', encoding='utf-8', level=logging.INFO)\n",
    "places_file = f\"./data/places_{region}.csv\"\n",
    "if not os.path.isfile(places_file):\n",
    "    points = points_from_country(region, level)\n",
    "    # points = points_from_country(\"Germany\", \"country\")\n",
    "\n",
    "    # entries for the same spot are grouped together\n",
    "    places = places_from_points(points)\n",
    "    # to later plot the difference between orgiginal and modified places\n",
    "    places[\"original_lat\"] = places[\"lat\"]\n",
    "    places[\"original_lon\"] = places[\"lon\"]\n",
    "    # possible cleaning reasons\n",
    "    # feature specifies the type of feature as str \n",
    "    # other reasons are binary\n",
    "    places[\"feature\"] = None\n",
    "    places[\"proximity\"] = False\n",
    "    places[\"road_delete\"] = False\n",
    "    places[\"road_distance\"] = False\n",
    "    places[\"road_segment\"] = False\n",
    "\n",
    "    places = gpd.GeoDataFrame(places, geometry=gpd.points_from_xy(places.lon, places.lat), crs=standard_crs)\n",
    "    places.to_csv(places_file)\n",
    "else:\n",
    "    places = pd.read_csv(places_file, index_col=0)\n",
    "    places = gpd.GeoDataFrame(places, geometry=gpd.points_from_xy(places.lon, places.lat), crs=standard_crs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"geometry\" is the feature that gets modified in our correction process\n",
    "# aligning the other features as to be done separately\n",
    "def update_places(places):\n",
    "    places[\"lon\"] = places.geometry.x\n",
    "    places[\"lat\"] = places.geometry.y\n",
    "    return places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_places(places, n_clusters=100, linkage=\"average\", distance_threshold=None):\n",
    "    places = update_places(places)\n",
    "    X = np.array(places[[\"lon\", \"lat\"]])\n",
    "    # with haversine distance we can use non metric crs\n",
    "    # and get distances in km\n",
    "    D = pairwise_distances(X, X, metric=haversine_lists, n_jobs=-1)\n",
    "\n",
    "    # hierarchical clustering technique\n",
    "    # clustering does not have to be perfect\n",
    "    # we want to cut the whole dataset of places into n_clusters chunks\n",
    "    # to handle each chunk separately -> this will save us compute\n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=n_clusters,\n",
    "        linkage=linkage,\n",
    "        compute_distances=True,\n",
    "        metric=\"precomputed\",\n",
    "        distance_threshold=distance_threshold\n",
    "    )\n",
    "    clustering.fit(D)\n",
    "\n",
    "    return clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO to check internals try:\n",
    "\n",
    "# plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "# # plot the top three levels of the dendrogram\n",
    "# plot_dendrogram(clustering, truncate_mode=\"level\", p=3)\n",
    "# plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "# plt.show()\n",
    "\n",
    "# with open(\"germany_100cluster_average_from_german_points.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(clustering, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3 Map Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the cluster count so that there are all clusters with at maximum x\n",
    "# this depends on the region chosen\n",
    "N_CLUSTERS = 100\n",
    "clustering = cluster_places(places, n_clusters=N_CLUSTERS)\n",
    "\n",
    "# assign a cluster to each place\n",
    "places[\"feature_cluster\"] = clustering.labels_\n",
    "\n",
    "# collect places that have already been changed (because they belong to a map feature)\n",
    "# to be modified in later pipeline steps\n",
    "PLACES_AT_FEATURES: List[Point] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance to a feature (potentially an area) in meters\n",
    "# for which a place should belong to the mentioned feature\n",
    "services_threshold = 30\n",
    "fuel_threshold = 30\n",
    "parking_threshold = 30\n",
    "# there are often streets close to ports; place should only be matched to port\n",
    "# if the hh used the port to get on a ship\n",
    "port_threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://github.com/gboeing/osmnx/blob/3822ed659f1cc9f426a990c02dd8ca6b3f4d56d7/osmnx/utils_geo.py#L420\n",
    "# blows up a place to be a circle\n",
    "def circle(place, radius):\n",
    "    point = place.geometry\n",
    "    earth_radius = 6_371_009  # meters\n",
    "    delta_lat = (radius / earth_radius) * (180 / np.pi)\n",
    "    return point.buffer(delta_lat)\n",
    "\n",
    "# let the places be circles and store this geometry as a separate feature\n",
    "places['services_geometry'] = places.progress_apply(lambda row: circle(row, services_threshold), axis=1)\n",
    "places['fuel_geometry'] = places.progress_apply(lambda row: circle(row, fuel_threshold), axis=1)\n",
    "places['parking_geometry'] = places.progress_apply(lambda row: circle(row, parking_threshold), axis=1)\n",
    "places['port_geometry'] = places.progress_apply(lambda row: circle(row, port_threshold), axis=1)\n",
    "\n",
    "# features to store the new (corrected) point geometry of a place\n",
    "# TODO necessary to have multiple places within one service area?\n",
    "places['service_corrected'] = None\n",
    "places['fuel_corrected'] = None\n",
    "places['parking_corrected'] = None\n",
    "# places in a port area should be merged as well\n",
    "# TODO think about if there are different places within a port area\n",
    "places['port_corrected'] = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run ~10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Run Feature\")\n",
    "warnings.simplefilter(action=\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "\n",
    "def get_close_feature(geometry, features):\n",
    "    relevant = features[features.intersects(geometry)]\n",
    "    if not relevant.empty:\n",
    "        # potentially there are multiple features close to a place\n",
    "        # we choose the first one\n",
    "        # and return get to corrected position of the place\n",
    "        single_feature = relevant.iloc[0]\n",
    "        return single_feature.geometry.centroid\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def correct_place(place):\n",
    "    new_location = None\n",
    "    feature = None\n",
    "    # reflects the precedence of features we want to match the places to\n",
    "    if place.port_corrected is not None:\n",
    "        new_location = place.port_corrected\n",
    "        feature = \"port\"\n",
    "    elif place.service_corrected is not None:\n",
    "        new_location = place.service_corrected\n",
    "        feature = \"service\"\n",
    "    elif place.fuel_corrected is not None:\n",
    "        new_location = place.fuel_corrected\n",
    "        feature = \"fuel\"\n",
    "    elif place.parking_corrected is not None:\n",
    "        new_location = place.parking_corrected\n",
    "        feature = \"parking\"\n",
    "\n",
    "    if new_location is not None:\n",
    "        # correct the place\n",
    "        return new_location, feature\n",
    "    else:\n",
    "        return place.geometry, None\n",
    "\n",
    "\n",
    "def feature_from_region(region: Polygon, tags: dict):\n",
    "    try:\n",
    "        features = osmnx.features.features_from_polygon(region, tags=tags)\n",
    "        return features\n",
    "    # InsufficientResponseError:\n",
    "    except Exception as e:\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, N_CLUSTERS)):\n",
    "    places_cluster = places.loc[places.feature_cluster == i]\n",
    "\n",
    "    # retrieving the OSM features that are relavant for the current cluster\n",
    "    places_in_cluster = MultiPolygon(places_cluster.services_geometry.to_list())\n",
    "    current_region = places_in_cluster.convex_hull\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # TODO query everything once and cache might result in a speedup here?!\n",
    "    # e.g. area=\"Germany\"; fuel = osmnx.features.features_from_place(area, tags={'amenity': 'fuel'})\n",
    "\n",
    "    # TODO try this\n",
    "    # # USE THIS\n",
    "    # # speedup\n",
    "    # cf = '[\"amenity\"~\"fuel|parking\"]'\n",
    "    # G = osmnx.graph_from_place(area, custom_filter=cf)\n",
    "    # cf = '[\"highway\"~\"services\"]'\n",
    "    # G = osmnx.graph_from_place(area, custom_filter=cf)\n",
    "    # fig, ax = osmnx.plot_graph(G)\n",
    "    # #\"natural\"~\"water\"\n",
    "\n",
    "    services = feature_from_region(current_region, tags={\"highway\": [\"services\", \"rest_area\"]})\n",
    "    # query both features at once is faster\n",
    "    fuel_parking = feature_from_region(\n",
    "        current_region, tags={\"amenity\": [\"parking\", \"fuel\"]}\n",
    "    )\n",
    "    port = feature_from_region(current_region, tags={\"industrial\": \"port\"})\n",
    "\n",
    "    logging.info(f\"OSM query time for features: {time.time() - start}\")\n",
    "    start = time.time()\n",
    "\n",
    "    if not services.empty:\n",
    "        try:\n",
    "            # polygons of service stations can be found via the \"way\" key\n",
    "            services = services.loc[\"way\"]\n",
    "            places.loc[\n",
    "                places.feature_cluster == i, \"service_corrected\"\n",
    "            ] = places_cluster.apply(\n",
    "                lambda place: get_close_feature(place.services_geometry, services),\n",
    "                axis=1,\n",
    "            )\n",
    "        except:\n",
    "            # there are no services in the region\n",
    "            pass\n",
    "\n",
    "    if not fuel_parking.empty:\n",
    "        fuel = fuel_parking.loc[fuel_parking.amenity == \"fuel\"]\n",
    "        parking = fuel_parking.loc[fuel_parking.amenity == \"parking\"]\n",
    "\n",
    "        places.loc[places.feature_cluster == i, \"fuel_corrected\"] = places_cluster.apply(\n",
    "            lambda place: get_close_feature(place.fuel_geometry, fuel), axis=1\n",
    "        )\n",
    "        places.loc[places.feature_cluster == i, \"parking_corrected\"] = places_cluster.apply(\n",
    "            lambda place: get_close_feature(place.parking_geometry, parking), axis=1\n",
    "        )\n",
    "\n",
    "    if not port.empty:\n",
    "        places.loc[places.feature_cluster == i, \"port_corrected\"] = places_cluster.apply(\n",
    "            lambda place: get_close_feature(place.port_geometry, port), axis=1\n",
    "        )\n",
    "\n",
    "    logging.info(f\"Time to match places to features: {time.time() - start}\")\n",
    "\n",
    "\n",
    "(\n",
    "    places[\"geometry\"],\n",
    "    places[\"feature\"],\n",
    ") = zip(*places.progress_apply(correct_place, axis=1))\n",
    "\n",
    "\n",
    "# we assume that you either hitchhike from a map feature or a road\n",
    "# save for later - if a place is attached to a feature it is protected from further changes\n",
    "places_at_feature = places.loc[places.feature.notnull()]\n",
    "# to treat places that are not a feature\n",
    "places = places[places.feature.isnull()]\n",
    "\n",
    "# mind that lat, lon of places are not changed yet - \"geometry\" contains the up-to-date location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Run Proximity\")\n",
    "\n",
    "# distance between spots in meter for which spots are seen as the same - transitive\n",
    "merge_threshold = 50\n",
    "merge_threshold = merge_threshold / 1000\n",
    "\n",
    "# calculate again because places are changed now\n",
    "# modification to clustering before: in one cluster there will not be places transitively more than merge_threshold apart\n",
    "clustering = cluster_places(places, n_clusters=None, linkage=\"single\", distance_threshold=merge_threshold)\n",
    "\n",
    "n_clusters = len(np.unique(clustering.labels_))\n",
    "places[\"proximity_cluster\"] = clustering.labels_\n",
    "\n",
    "# merge places to the centroid of their group\n",
    "for cluster in tqdm(range(0, n_clusters)):\n",
    "    if len(places[places.proximity_cluster == cluster]) > 1:\n",
    "        merged_location = places[places.proximity_cluster == cluster].geometry.unary_union.centroid\n",
    "        places.loc[places.proximity_cluster == cluster, [\"geometry\", \"proximity\"]] = merged_location, True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-9 Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Run Road\")\n",
    "\n",
    "places = update_places(places)\n",
    "\n",
    "# using a metric coordinate system here for distance calculation\n",
    "places.to_crs(metric_crs, inplace=True)\n",
    "\n",
    "# new features - identifier of the nearest road segement and new location closer to a road\n",
    "places[['nearest_road','road_correction']] = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handles a \"line\" composed of one or more line segments.\n",
    "def cut(line: LineString, distance: float) -> List[LineString]:\n",
    "    # Cuts a line in two at a distance from its starting point\n",
    "    if distance <= 0.0 or distance >= line.length:\n",
    "        return [LineString(line)]\n",
    "    coords = list(line.coords)\n",
    "    # iterate through the line segments\n",
    "    for i, point in enumerate(coords):\n",
    "        # calculate the distance from the starting point to the point of the current line segment\n",
    "        point_distance = line.project(Point(point))\n",
    "        if point_distance == distance:\n",
    "            return [\n",
    "                LineString(coords[:i+1]),\n",
    "                LineString(coords[i:])]\n",
    "        if point_distance > distance:\n",
    "            # get the point on the line that is distance away from the starting point\n",
    "            # this has to lie on the current line segment\n",
    "            # thus we have to make the cut in this segment\n",
    "            cutting_point = line.interpolate(distance)\n",
    "            return [\n",
    "                LineString(coords[:i] + [(cutting_point.x, cutting_point.y)]),\n",
    "                LineString([(cutting_point.x, cutting_point.y)] + coords[i:])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above seems like the place was not meant to be on a road or the creator did not take any effort to place\n",
    "# it accurately on the road - in either case the place can be deleted as it introduces noise\n",
    "road_upper_threshold = 100\n",
    "# below places are considered accurate enough - the user will know which road the spot is related to\n",
    "road_lower_threshold = 30\n",
    "# distance to use when searching for road points around a place\n",
    "# road points should be frequent but are definitely further away than the direct distance to the road\n",
    "# at important marks of a road there are road (ancor) points\n",
    "# thus one can assume that when the place is close to a road but not close enough to a road point that it is placed\n",
    "# at a location where you can/ should not hitchhike\n",
    "road_search_radius = 300\n",
    "\n",
    "\n",
    "def get_nearest_road(place):\n",
    "    # OSM query could fail\n",
    "    try:\n",
    "        # query a graph of all roads around the place\n",
    "        # using lat, lon in geometric coordinates here - make sure they are up-to-date\n",
    "        # TODO bound by api queries - can this be done more efficient?\n",
    "        roads = osmnx.graph.graph_from_point(\n",
    "            (place.lat, place.lon),\n",
    "            dist=road_search_radius,\n",
    "            network_type=\"drive\",\n",
    "            retain_all=True,\n",
    "            truncate_by_edge=True,\n",
    "        )\n",
    "        roads = osmnx.projection.project_graph(roads, to_crs=metric_crs)\n",
    "        # get the nearest road to the place\n",
    "        # returns nearest edges as (u, v, key)\n",
    "        nearest = osmnx.distance.nearest_edges(\n",
    "            roads, place.geometry.x, place.geometry.y, return_dist=True\n",
    "        )\n",
    "        road = nearest[0]\n",
    "        dist = nearest[1]\n",
    "        # identify road by its nodes\n",
    "        road_name = f\"{road[0]}-{road[1]}\"\n",
    "\n",
    "        if dist > road_upper_threshold:\n",
    "            # for this case delete the place\n",
    "            return None, None\n",
    "        elif road_lower_threshold < dist <= road_upper_threshold:\n",
    "            # get the coordinates of new spot that is moved closer to the road than original spot\n",
    "            # translate the road into a geometry object\n",
    "            _, gdf_roads = osmnx.utils_graph.graph_to_gdfs(roads)\n",
    "            road_geom = gdf_roads.loc[road].geometry\n",
    "            # get the point on the road that is closest to the place to project the place on the road\n",
    "            # first point would be the place itself\n",
    "            nearest_point = nearest_points(place.geometry, road_geom)[1]\n",
    "            # move the place to the road but not directly on it\n",
    "            # using LineString here as the generalization of a line\n",
    "            # osm graph and gdf use LineString as well to describe road segments\n",
    "            tangent_line = LineString([nearest_point, place.geometry])\n",
    "            cut_line = cut(tangent_line, road_lower_threshold)\n",
    "            return road_name, Point(cut_line[0].coords[-1])\n",
    "        else:\n",
    "            # if the place is already placed accurately enough on the road we want to know which road it belongs to\n",
    "            # but do not need to adjust the place\n",
    "            return road_name, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# introduce new features\n",
    "# id of the nearest road\n",
    "# and corrected location\n",
    "(\n",
    "    places[\"nearest_road\"],\n",
    "    places[\"road_correction\"],\n",
    ") = zip(*places.progress_apply(get_nearest_road, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to retransform because in the previous step we used a metric coordinate system\n",
    "crs_transformer = pyproj.Transformer.from_crs(metric_crs, standard_crs)\n",
    "places.to_crs(standard_crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete points that are not related to a road nor to a map feature\n",
    "places.loc[places.nearest_road.isna(), \"road_delete\"] = True\n",
    "# save for later - if a place is deleted it is not treated further\n",
    "places_deleted = places[places.road_delete]\n",
    "# to treat places that are not a feature\n",
    "places = places[~places.road_delete]\n",
    "\n",
    "\n",
    "# TODO in human tool - give chance to move the spot to a suitable location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct spots to their new location at the road\n",
    "\n",
    "\n",
    "# give places their new location closer to their road\n",
    "def attach_place_to_road(place):\n",
    "    if place.road_correction is not None:\n",
    "        lat, lon = crs_transformer.transform(\n",
    "            place.road_correction.x, place.road_correction.y\n",
    "        )\n",
    "        return Point(lon, lat), True\n",
    "    else:\n",
    "        return place.geometry, False\n",
    "\n",
    "\n",
    "(\n",
    "    places[\"geometry\"],\n",
    "    places[\"road_distance\"],\n",
    ") = zip(*places.progress_apply(attach_place_to_road, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO drop? - most examples where this was applied came with informatin loss\n",
    "# only do it for road segements with length < X meters\n",
    "\n",
    "# find groups of places that are at the same road segment so they can be merged\n",
    "places_by_road_segment = places.groupby(\"nearest_road\")\n",
    "\n",
    "for group_id, places_group_at_road_segment in tqdm(places_by_road_segment):\n",
    "    if len(places_group_at_road_segment) > 1:\n",
    "        place_indices_at_road_segment = places_group_at_road_segment.index\n",
    "        # TODO better solution than centroid here?\n",
    "        # use latest comment or place with most comments instead\n",
    "        merged_location = places.loc[place_indices_at_road_segment].geometry.unary_union.centroid\n",
    "        places.loc[place_indices_at_road_segment, \"geometry\"] = merged_location\n",
    "        places.loc[place_indices_at_road_segment, \"road_segment\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine all places that were treated separately\n",
    "cleaned_places = pd.concat([places, places_at_feature, places_deleted])\n",
    "cleaned_places = update_places(cleaned_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_stats(cleaned_places)\n",
    "with open(f\"./stats/stats_{region}.txt\", \"w\") as f:\n",
    "    f.write(str(stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference map\n",
    "# green points are from the new cleaned map vs red points from the original map\n",
    "\n",
    "def save_as_map(places_to_save, set_of_places=\"normal\"):\n",
    "    map = folium.Map(prefer_canvas=True, control_scale=True)\n",
    "\n",
    "    def dot(lat, lon, color):\n",
    "        folium.CircleMarker([lat, lon], opacity=0.0, radius=5, fillOpacity=1.0, fillColor=color).add_to(map)\n",
    "\n",
    "    def line(lat1, lon1, lat2, lon2, color):\n",
    "        folium.PolyLine([(lat1, lon1), (lat2, lon2)], color=color).add_to(map)\n",
    "\n",
    "    for country, group in places_to_save.groupby(\"country_group\"):\n",
    "        for index, place in group.iterrows():\n",
    "            if place.road_delete:\n",
    "                dot(place.lat, place.lon, \"black\")\n",
    "            else:\n",
    "                dot(place.lat, place.lon, \"lightgreen\")\n",
    "                # if the place did not change only the red dot is visible\n",
    "                dot(place.original_lat, place.original_lon, \"red\")\n",
    "\n",
    "                correction_line_color = None\n",
    "                if place.feature != None:\n",
    "                    correction_line_color = \"orange\"\n",
    "                # after proximity merge places can still get moved/ merged because of there relation to a road\n",
    "                elif place.road_segment:\n",
    "                    correction_line_color = \"purple\"\n",
    "                elif place.road_distance:\n",
    "                    correction_line_color = \"green\"\n",
    "                elif place.proximity:\n",
    "                    correction_line_color = \"blue\"\n",
    "                \n",
    "                \n",
    "                if correction_line_color is not None:\n",
    "                    line(place.lat, place.lon, place.original_lat, place.original_lon, correction_line_color)\n",
    "\n",
    "    # show\n",
    "    map.save(f\"./map/{set_of_places}/map_{region}.html\")\n",
    "\n",
    "save_as_map(places_to_save=cleaned_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_places[\"latlon\"] = cleaned_places.apply(lambda row: f\"{row.lat}{row.lon}\", axis=1)\n",
    "places_to_save = cleaned_places[cleaned_places.duplicated(subset=\"latlon\", keep=False)]\n",
    "save_as_map(places_to_save=places_to_save, set_of_places=\"merging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_places[~cleaned_places.feature.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_to_save = cleaned_places[cleaned_places.proximity]\n",
    "save_as_map(places_to_save=places_to_save, set_of_places=\"proximity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO still have to perform the actual merge on both places and underlying points\n",
    "\n",
    "# eventually store results\n",
    "cleaned_places.to_csv(f'data/cleaned_places_{region}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
